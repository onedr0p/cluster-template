---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2beta1.json
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: rook-ceph-cluster
spec:
  interval: 15m
  chart:
    spec:
      chart: rook-ceph-cluster
      version: v1.12.4
      sourceRef:
        kind: HelmRepository
        name: rook-ceph-charts
        namespace: flux-system
      interval: 15m
  install:
    createNamespace: true
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  values:
    operatorNamespace: rook-ceph
    toolbox:
      enabled: true
      resources:
        requests:
          cpu: 15m
          memory: 105Mi
        limits:
          memory: 105Mi
    ingress:
      dashboard:
        ingressClassName: nginx
        annotations:
          nginx.ingress.kubernetes.io/whitelist-source-range: |
            10.244.0.0/16,10.10.0.0/24,192.168.50.0/24,192.168.10.0/24,192.168.200.0/24
        host:
          name: &host rook.${SECRET_DOMAIN_0}
          paths: /
        tls:
          - hosts:
              - *host
            secretName: ${SECRET_DOMAIN_0//./-}-prod-tls
    monitoring:
      enabled: true
      createPrometheusRules: true
    pspEnable: false
    cephClusterSpec:
      dataDirHostPath: /var/lib/rook
      skipUpgradeChecks: false
      continueUpgradeAfterChecksEvenIfNotHealthy: false
      waitTimeoutForHealthyOSDInMinutes: 10
      mon:
        count: 3
        allowMultiplePerNode: false
      mgr:
        count: 1
        modules:
          - name: pg_autoscaler
            enabled: true
      dashboard:
        enabled: true
        port: 8443
        ssl: false
      crashCollector:
        disable: false
      cleanupPolicy:
        confirmation: ""
        sanitizeDisks:
          method: quick
          dataSource: zero
          iteration: 1
        allowUninstallWithVolumes: false
      removeOSDsIfOutAndSafeToRemove: false
      priorityClassNames:
        mon: system-node-critical
        osd: system-node-critical
        mgr: system-cluster-critical
      storage:
        useAllNodes: true
        useAllDevices: true
      disruptionManagement:
        managePodBudgets: true
        osdMaintenanceTimeout: 30
        pgHealthCheckTimeout: 0
        manageMachineDisruptionBudgets: false
        machineDisruptionBudgetNamespace: openshift-machine-api
      healthCheck:
        daemonHealth:
          mon:
            disabled: false
            interval: 45s
          osd:
            disabled: false
            interval: 60s
          status:
            disabled: false
            interval: 60s
        livenessProbe:
          mon:
            disabled: false
          mgr:
            disabled: false
          osd:
            disabled: false
        startupProbe:
          mon:
            disabled: false
          mgr:
            disabled: false
          osd:
            disabled: false
      resources: null
    cephBlockPools:
      - name: blockpool
        spec:
          failureDomain: host
          replicated:
            size: 3
        storageClass:
          enabled: true
          name: rook-ceph-block
          isDefault: true
          reclaimPolicy: Delete
          allowVolumeExpansion: true
          mountOptions: []
          parameters:
            imageFormat: "2"
            imageFeatures: layering
            csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
            csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
            csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
            csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
            csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
            csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
            csi.storage.k8s.io/fstype: ext4
    cephFileSystems: null
    cephObjectStores: null
